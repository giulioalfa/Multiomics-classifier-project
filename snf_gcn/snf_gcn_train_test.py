# -*- coding: utf-8 -*-
"""mlp_gcn_train_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bNasryE-nEkwuJJEeaEeASnbclUD2Gip
"""

import os
import numpy as np
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score
import torch
import torch.nn.functional as F
from snf_gcn_models import init_model_dict, init_optim
from utils import one_hot_tensor, cal_sample_weight, to_sparse
from snfpy import snf

cuda = True if torch.cuda.is_available() else False

# train and test dateset and labels loading
def prepare_trte_data(data_folder, view_list):
    num_view = len(view_list)
    labels_tr = np.loadtxt(os.path.join(data_folder, "labels_tr.csv"), delimiter=',')
    labels_te = np.loadtxt(os.path.join(data_folder, "labels_te.csv"), delimiter=',')
    labels_tr = labels_tr.astype(int)
    labels_te = labels_te.astype(int)
    data_tr_list = []
    data_te_list = []
    for i in view_list:
        data_tr_list.append(np.loadtxt(os.path.join(data_folder, str(i)+"_tr.csv"), delimiter=','))
        data_te_list.append(np.loadtxt(os.path.join(data_folder, str(i)+"_te.csv"), delimiter=','))
    
      

    num_tr = data_tr_list[0].shape[0]
    num_te = data_te_list[0].shape[0]
    data_mat_list = []
    
    
    #compute snf for train set
    affinity_omic1_train = snf.compute.make_affinity(data_tr_list[0], metric="euclidean", K= 20, mu=0.5, normalize=True)
    affinity_omic2_train = snf.compute.make_affinity(data_tr_list[1], metric="euclidean", K= 20, mu=0.5, normalize=True)
    affinity_omic3_train = snf.compute.make_affinity(data_tr_list[2], metric="euclidean", K= 20, mu=0.5, normalize=True)
    affinity_networks_train = snf.compute.snf(affinity_omic1_train, affinity_omic2_train, affinity_omic3_train, )
    
    fused_snf_train = torch.FloatTensor(affinity_networks_train)
    #compute snf for test set
    affinity_omic1_test = snf.compute.make_affinity(data_te_list[0], metric="euclidean", K= 20, mu=0.5, normalize=True)
    affinity_omic2_test = snf.compute.make_affinity(data_te_list[1], metric="euclidean", K= 20, mu=0.5, normalize=True)
    affinity_omic3_test = snf.compute.make_affinity(data_te_list[2], metric="euclidean", K= 20, mu=0.5, normalize=True)
    affinity_omics_test = snf.compute.snf(affinity_omic1_test, affinity_omic2_test, affinity_omic3_test, )

    
    
    fused_snf_test = torch.FloatTensor(affinity_omics_test)
    early_aggregation_train = np.concatenate((data_tr_list[0], data_tr_list[1], data_tr_list[2]), axis = 1)
    early_aggregation_test = np.concatenate((data_te_list[0], data_te_list[1], data_te_list[2]), axis = 1)
    
    early_aggregation_all = np.concatenate((early_aggregation_train, early_aggregation_test))
    
    print("snf computed")
    for i in range(num_view):
        data_mat_list.append(np.concatenate((data_tr_list[i], data_te_list[i]), axis=0))

    
    data_mat_list.append(early_aggregation_all)
    affinity_omic1_trte = snf.compute.make_affinity(data_mat_list[0], metric="euclidean", K= 20, mu=0.5, normalize=True)
    affinity_omic2_trte = snf.compute.make_affinity(data_mat_list[1], metric="euclidean", K= 20, mu=0.5, normalize=True)
    affinity_omic3_trte = snf.compute.make_affinity(data_mat_list[2], metric="euclidean", K= 20, mu=0.5, normalize=True)
    fused_snf_trte = snf.compute.snf(affinity_omic1_trte, affinity_omic2_trte, affinity_omic3_trte)
    
    data_tensor_list = []
    for i in range(len(data_mat_list)):
        data_tensor_list.append(torch.FloatTensor(data_mat_list[i]))
        if cuda:
            data_tensor_list[i] = data_tensor_list[i].cuda()


    idx_dict = {}
    idx_dict["tr"] = list(range(num_tr))
    idx_dict["te"] = list(range(num_tr, (num_tr+num_te)))
    data_train_list = []
    data_all_list = []
    
    data_train_list.append(data_tensor_list[3][idx_dict["tr"]].clone())
    data_all_list.append(torch.cat((data_tensor_list[3][idx_dict["tr"]].clone(),
                                       data_tensor_list[3][idx_dict["te"]].clone()),0))
    

    labels = np.concatenate((labels_tr, labels_te))
    fused_snf_train = torch.FloatTensor(fused_snf_train)
    fused_snf_trte = torch.FloatTensor(fused_snf_trte)
    
    return data_train_list, data_all_list, idx_dict, labels, fused_snf_train, fused_snf_trte

#train and test SNF adjacency matrix are sparse 
def gen_trte_adj_mat(fused_snf_train, fused_snf_test):
    
    adj_train_list = []
    adj_test_list = []
    
    adj_train_list.append(to_sparse(fused_snf_train))
    adj_test_list.append(to_sparse(fused_snf_test))
    
    return adj_train_list[0], adj_test_list[0]

#train epoch: forward and backward
def train_epoch(data_list, adj_list, label, one_hot_label, sample_weight, model_dict, optim_dict, train_VCDN=True):
    loss_dict = {}
    criterion = torch.nn.CrossEntropyLoss(reduction='none')
    for m in model_dict:
        model_dict[m].train()    
    num_view = len(data_list)
    for i in range(num_view):
       
      optim_dict["C{:}".format(i+1)].zero_grad()
      ci_loss = 0
      ci = model_dict["C{:}".format(i+1)](model_dict["E{:}".format(i+1)](data_list[i],adj_list))
      ci_loss = torch.mean(torch.mul(criterion(ci, label),sample_weight))
      ci_loss.backward()
      optim_dict["C{:}".format(i+1)].step()
      loss_dict["C{:}".format(i+1)] = ci_loss.detach().cpu().numpy().item()      
      
    
    
    return loss_dict
    
#test
def test_epoch(data_list, adj_list, te_idx, model_dict):
    for m in model_dict:
        model_dict[m].eval()
    num_view = len(data_list)
    ci_list = []
    for i in range(num_view):
      

      ci_list.append(model_dict["C{:}".format(i+1)](model_dict["E{:}".format(i+1)](data_list[i],adj_list)))
          
        
       
    
    c = ci_list[0]
    c = c[te_idx,:]
    prob = F.softmax(c, dim=1).data.cpu().numpy()
    
    return prob

#main method : prepare dataset, train and test
def train_test(data_folder, view_list, num_class,
               lr_e_pretrain, lr_e, lr_c, 
               num_epoch_pretrain, num_epoch):
    test_inverval = 50
    num_view = len(view_list)-2
    dim_hvcdn = pow(num_class,num_view)
    dataset_path = "Data/" 
    if data_folder == dataset_path + 'ROSMAP':
        adj_parameter = 2
        dim_he_list = [200,200,100]
    if data_folder == dataset_path + 'BRCA':
        adj_parameter = 10
        dim_he_list = [400,400,200]
    if data_folder == dataset_path + 'GDCDATASET_N' or data_folder == dataset_path + "LuadLusc100" or data_folder == dataset_path + "5000samples":
        adj_parameter = 10
        dim_he_list = [400,400,200]
    data_tr_list, data_trte_list, trte_idx, labels_trte, fused_snf_train, fused_snf_test = prepare_trte_data(data_folder, view_list)
    
    labels_tr_tensor = torch.LongTensor(labels_trte[trte_idx["tr"]])
    onehot_labels_tr_tensor = one_hot_tensor(labels_tr_tensor, num_class)
    sample_weight_tr = cal_sample_weight(labels_trte[trte_idx["tr"]], num_class)
    sample_weight_tr = torch.FloatTensor(sample_weight_tr)
    if cuda:
        labels_tr_tensor = labels_tr_tensor.cuda()
        onehot_labels_tr_tensor = onehot_labels_tr_tensor.cuda()
        sample_weight_tr = sample_weight_tr.cuda()
    adj_tr_list, adj_te_list = gen_trte_adj_mat(fused_snf_train, fused_snf_test)
    dim_list = [x.shape[1] for x in data_tr_list]
    model_dict = init_model_dict(num_view, num_class, dim_list, dim_he_list, dim_hvcdn)
    for m in model_dict:
        if cuda:
            model_dict[m].cuda()
    
    print("\nPretrain GCNs...")
    optim_dict = init_optim(num_view, model_dict, lr_e_pretrain, lr_c)
    for epoch in range(num_epoch_pretrain):
        train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, 
                    onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict, train_VCDN=False)
    print("\nTraining...")
    optim_dict = init_optim(num_view, model_dict, lr_e, lr_c)
    for epoch in range(num_epoch+1):
        train_epoch(data_tr_list, adj_tr_list, labels_tr_tensor, 
                    onehot_labels_tr_tensor, sample_weight_tr, model_dict, optim_dict)
        if epoch % test_inverval == 0:
            te_prob = test_epoch(data_trte_list, adj_te_list, trte_idx["te"], model_dict)
            print("\nTest: Epoch {:d}".format(epoch))
            if num_class == 2:
                print("Test ACC: {:.3f}".format(accuracy_score(labels_trte[trte_idx["te"]], te_prob.argmax(1))))
                print("Test F1: {:.3f}".format(f1_score(labels_trte[trte_idx["te"]], te_prob.argmax(1))))
                print("Test AUC: {:.3f}".format(roc_auc_score(labels_trte[trte_idx["te"]], te_prob[:,1])))
            else:
                print("Test ACC: {:.3f}".format(accuracy_score(labels_trte[trte_idx["te"]], te_prob.argmax(1))))
                print("Test F1 weighted: {:.3f}".format(f1_score(labels_trte[trte_idx["te"]], te_prob.argmax(1), average='weighted')))
                print("Test F1 macro: {:.3f}".format(f1_score(labels_trte[trte_idx["te"]], te_prob.argmax(1), average='macro')))
            print()